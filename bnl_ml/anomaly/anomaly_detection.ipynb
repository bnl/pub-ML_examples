{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show an example of training 3 different models for unsupervised anomaly detection:\n",
    "* Elliptical Envelope\n",
    "* Local Outlier Detection\n",
    "* Isolation Forest\n",
    "\n",
    "The models are optimized via cross-validation using custom metrics defined below\n",
    "\n",
    "Since we transform the original data via Principle Components Analysis (PCA), the preparatory steps and the model itself can be combined into a pipeline:\n",
    "1) Standartization of each feature across the training set\n",
    "\n",
    "2) PCA transformation\n",
    "\n",
    "3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit, train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from load_data import process_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data \n",
    "\n",
    "Select `from_csv = True` if the data have been preprocessed and saved to a csv file already. \n",
    "\n",
    "Alternatevely, select `from_csv = False` if the raw hdf5 files need to be processed. in this case, indicate path to the data directory `data_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_csv = True\n",
    "data_dir = None # '../data/all_hdf5/*.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if from_csv:\n",
    "    df = pd.read_csv('CSX_data.csv', index_col = 0)\n",
    "else:\n",
    "    df = process_files(path = data_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal data size: 399\n",
      "Anomaly data size: 328\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_normal = df[df.target == 'normal'][:].sample(frac = 1, random_state = 10)\n",
    "df_anomaly = df[df.target == 'anomaly'][:].sample(frac = 1, random_state = 10)\n",
    "\n",
    "print(f'Normal data size: {df_normal.shape[0]}')\n",
    "print(f'Anomaly data size: {df_anomaly.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "* train: 80% of normal data \n",
    "* validation: 10% of normal data and 50% of anomalous data\n",
    "* test: 10% of normal data and 50% of anomalous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training data shape: (312, 95) \n",
      " validation data shape:(203, 95) \n",
      " test data shape: (212, 95)\n"
     ]
    }
   ],
   "source": [
    "# splitting points for nomal data\n",
    "normal_split1 = (df_normal.shape[0]//10)*8\n",
    "normal_split2 = (df_normal.shape[0]//10)*1 + normal_split1\n",
    "\n",
    "train = df_normal.iloc[:normal_split1, :]\n",
    "val_normal = df_normal.iloc[normal_split1:normal_split2, :]\n",
    "test_normal = df_normal.iloc[normal_split2:, :]\n",
    "\n",
    "# splitting poin for anomaly data\n",
    "anomaly_split = df_anomaly.shape[0]//2\n",
    "\n",
    "val_anomaly = df_anomaly.iloc[:anomaly_split, :]\n",
    "test_anomaly = df_anomaly.iloc[anomaly_split:, :]\n",
    "\n",
    "val = pd.concat([val_normal, val_anomaly]).reset_index(drop=True)\n",
    "test = pd.concat([test_normal, test_anomaly]).reset_index(drop=True)\n",
    "\n",
    "print(f'\\n training data shape: {train.shape} \\n validation data shape:{val.shape} \\n test data shape: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate data into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['target', 'roi'])\n",
    "target = train['target'].map({'anomaly': -1, 'normal': 1})\n",
    "\n",
    "X_val = val.drop(columns = ['target', 'roi'])\n",
    "target_val = val['target'].map({'anomaly': -1, 'normal': 1})\n",
    "\n",
    "X_test = test.drop(columns = ['target', 'roi'])\n",
    "target_test = test['target'].map({'anomaly': -1, 'normal': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct (training, validation) split to use for model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine training and validation features and targets for them to have consistent indexes\n",
    "X_comb = pd.concat([X, X_val]).reset_index(drop=True)\n",
    "target_comb = pd.concat([target, target_val]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# split the sets again, now the indexes are consistent\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_comb, target_comb, \n",
    "                                                  train_size=X.shape[0], random_state = None,\n",
    "                                                  shuffle = False)\n",
    "# define the split\n",
    "split_index = [-1 if x in X_train.index else 0 for x in X_comb.index]\n",
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom performance metrics\n",
    "\n",
    "The metric we select here tries to simultaneously increase recalls for anomalies and normal cases and reduce false classification for both labels. The metric can be used directly in grid search optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_recalls(y, y_pred):\n",
    "    anomaly_recall = recall_score(-y, -y_pred)\n",
    "    normal_recall = recall_score(y, y_pred)\n",
    "    anomaly_precision = precision_score(-y,-y_pred)\n",
    "    normal_precision = precision_score(y, y_pred)\n",
    "    \n",
    "    score = anomaly_recall*normal_recall*normal_precision*anomaly_precision\n",
    "    return score\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "score = make_scorer(combined_recalls, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the models we identify the set of parameters we want to optimize and the range of the values we would like to consider. The search for the optimal set of the parameters' values is done via GridSearchCV ( exhaustive search and cross-validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elliptic Envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For elliptical envelope we only vary the number of principle components and the contamination level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'pca__n_components':np.arange(1,40),\n",
    "         'model__contamination': np.linspace(0, 0.5, 20)}\n",
    "\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca', PCA()),\n",
    "                 ('model', EllipticEnvelope(assume_centered=False, random_state = 50))]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, params, n_jobs = -1, cv=pds, scoring = score, refit=False)\n",
    "_= grid.fit(X_comb,target_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA(n_components=3)),\n",
       "                ('model',\n",
       "                 EllipticEnvelope(contamination=0.13157894736842105,\n",
       "                                  random_state=50))])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contamination = grid.best_params_['model__contamination']\n",
    "n_pca = grid.best_params_['pca__n_components']\n",
    "best_EE = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca', PCA(n_pca)),\n",
    "                 ('model', EllipticEnvelope(assume_centered=False, random_state = 50, contamination =contamination))]) \n",
    "best_EE.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "We consider confusion matrix and precision and false discovery rate of anomalous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            anomaly_M   normal_M\n",
      " anomaly_T    161        3\n",
      " normal_T       6       42\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(target_test, best_EE.predict(X_test))\n",
    "print(\n",
    "f'            anomaly_M   normal_M\\n \\\n",
    "anomaly_T    {cmat[0][0]}        {cmat[0][1]}\\n \\\n",
    "normal_T       {cmat[1][0]}       {cmat[1][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall = 98.2%\n",
      "false discovery rate = 3.6%\n",
      "roc_auc = 0.93\n"
     ]
    }
   ],
   "source": [
    "print(f'recall = {recall_score(-target_test,-best_EE.predict(X_test)):2.1%}')\n",
    "print(f'false discovery rate = {1 - precision_score(-target_test,-best_EE.predict(X_test)):2.1%}')\n",
    "print(f'roc_auc = {auc(-target_test,-best_EE.predict(X_test)):1.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'pca__n_components':np.arange(1,20),\n",
    "          'model__contamination': np.linspace(0.0, 0.5, 30),\n",
    "          'model__n_neighbors':np.arange(1, 25, 2),\n",
    "          'model__leaf_size' : np.arange(1, 40, 5)}\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca', PCA()),\n",
    "                 ('model', LocalOutlierFactor(novelty = True, algorithm='kd_tree'))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, params, n_jobs = -1, cv=pds, scoring = score, refit=False)\n",
    "_ = grid.fit(X_comb,target_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA(n_components=3)),\n",
       "                ('model',\n",
       "                 LocalOutlierFactor(algorithm='kd_tree',\n",
       "                                    contamination=0.10344827586206896,\n",
       "                                    leaf_size=1, n_neighbors=7,\n",
       "                                    novelty=True))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = grid.best_params_\n",
    "best_LOD = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca', PCA(params['pca__n_components'])),\n",
    "                 ('model', LocalOutlierFactor(novelty = True, algorithm ='kd_tree',\n",
    "                                             contamination = params['model__contamination'],\n",
    "                                             n_neighbors = params['model__n_neighbors'],\n",
    "                                             leaf_size = params['model__leaf_size']))]) \n",
    "best_LOD.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            anomaly_M   normal_M\n",
      " anomaly_T    152        12\n",
      " normal_T       5       43\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(target_test, best_LOD.predict(X_test))\n",
    "print(\n",
    "f'            anomaly_M   normal_M\\n \\\n",
    "anomaly_T    {cmat[0][0]}        {cmat[0][1]}\\n \\\n",
    "normal_T       {cmat[1][0]}       {cmat[1][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall = 92.7%\n",
      "false discovery rate = 3.2%\n",
      "roc_auc = 0.91\n"
     ]
    }
   ],
   "source": [
    "print(f'recall = {recall_score(-target_test,-best_LOD.predict(X_test)):2.1%}')\n",
    "print(f'false discovery rate = {1 - precision_score(-target_test,-best_LOD.predict(X_test)):2.1%}')\n",
    "print(f'roc_auc = {auc(-target_test,-best_LOD.predict(X_test)):1.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the above models, the number of avaiable model parameters (particularly, the maximum number of features for building an isolation tree) for Isolation Forest is dependent on the number of principle components. Thus, we change the number of components in a `for`-loop and run a grid search at each step of the loop and keep track of the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pca = 0\n",
    "best_score = 0\n",
    "\n",
    "for j in range(1, 5):\n",
    "      \n",
    "    params = {'model__max_features': np.arange(1, j+1),\n",
    "              'model__contamination': np.linspace(0, 0.5, 20)}\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca', PCA(j)),\n",
    "                 ('model', IsolationForest(\n",
    "                      \n",
    "                      n_estimators = 300,                      \n",
    "                      bootstrap=True,\n",
    "                      n_jobs=-1,\n",
    "                      behaviour='deprecated',\n",
    "                      random_state=10,\n",
    "                      verbose=0,\n",
    "                      warm_start=False))]) \n",
    "    \n",
    "    grid = GridSearchCV(pipe, params, n_jobs = -1, cv=pds, scoring = score, refit = False)\n",
    "    grid.fit(X_comb,target_comb)\n",
    "    params = grid.best_params_\n",
    "    \n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca', PCA(j)),\n",
    "                 ('model', IsolationForest(\n",
    "                      max_samples='auto',\n",
    "                      n_estimators = 300,                      \n",
    "                      bootstrap=True,\n",
    "                      n_jobs=-1,\n",
    "                      behaviour='deprecated',\n",
    "                      random_state=10,\n",
    "                      verbose=0,\n",
    "                      warm_start=True,\n",
    "                 max_features = params['model__max_features'],\n",
    "                 contamination = params['model__contamination']))]).fit(X_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    if grid.best_score_ > best_score:\n",
    "        best_score = grid.best_score_\n",
    "        best_pca = j\n",
    "        best_pipe = pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            anomaly_M   normal_M\n",
      " anomaly_T    162        2\n",
      " normal_T       11       37\n"
     ]
    }
   ],
   "source": [
    "cmat = confusion_matrix(target_test, best_IFT.predict(X_test))\n",
    "print(\n",
    "f'            anomaly_M   normal_M\\n \\\n",
    "anomaly_T    {cmat[0][0]}        {cmat[0][1]}\\n \\\n",
    "normal_T       {cmat[1][0]}       {cmat[1][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall = 98.8%\n",
      "false discovery rate = 6.4%\n",
      "roc_auc = 0.88\n"
     ]
    }
   ],
   "source": [
    "print(f'recall = {recall_score(-target_test,-best_IFT.predict(X_test)):2.1%}')\n",
    "print(f'false discovery rate = {1 - precision_score(-target_test,-best_IFT.predict(X_test)):2.1%}')\n",
    "print(f'roc_auc = {auc(-target_test,-best_IFT.predict(X_test)):1.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model on new data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a model among the best predictors based on your preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = best_EE\n",
    "new_data_file = '../data/all_hdf5/EELKGWIGY.h5' # this file was used for the model, here is considered for demostration only\n",
    "\n",
    "new_data = process_files(path = new_data_file).drop(columns = ['target', 'roi']).values\n",
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
